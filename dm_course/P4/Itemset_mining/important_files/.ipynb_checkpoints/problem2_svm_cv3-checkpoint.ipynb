{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Items Containing 100:  96\n",
      "Frequent Items Containing 200:  90\n"
     ]
    }
   ],
   "source": [
    "f = open('outfile_freq_sup20.txt', \"r\").readlines()\n",
    "f = [line.strip('\\n') for line in f]\n",
    "f = [line.split(\",\") for line in f]\n",
    "f = [line[:-1] for line in f]\n",
    "\n",
    "itemSets = []\n",
    "sups = []\n",
    "hits100=0\n",
    "hits200=0\n",
    "d={}\n",
    "counter=0\n",
    "for line in f:\n",
    "    \n",
    "    if '100' in line[:-1]:\n",
    "        hits100+=1\n",
    "    if '200' in line[:-1]:\n",
    "        hits200+=1\n",
    "    itemSets.append(line[:-1])\n",
    "    sups.append(line[-1])\n",
    "    d[counter]=(line[:-1], line[-1])\n",
    "    counter+=1\n",
    "    \n",
    "print 'Frequent Items Containing 100: ', hits100\n",
    "print 'Frequent Items Containing 200: ', hits200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Frequent Item sets with Highest Support\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, (['6'], '0.776316')),\n",
       " (2, (['16'], '0.644737')),\n",
       " (6, (['200'], '0.631579')),\n",
       " (13, (['2'], '0.605263')),\n",
       " (22, (['5'], '0.592105')),\n",
       " (14, (['5', '6'], '0.578947')),\n",
       " (36, (['14'], '0.565789')),\n",
       " (63, (['13'], '0.565789')),\n",
       " (79, (['3'], '0.552632')),\n",
       " (23, (['14', '6'], '0.539474'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Top 10 Most Frequent Item sets with Highest Support'\n",
    "sorted(d.items(), key=lambda x: x[1][1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Association Rules In Terms of Confidence with Head 100: 70\n",
      "Top 10 Association Rules In Terms of Confidence with Head 200: 105\n"
     ]
    }
   ],
   "source": [
    "f2 = open('outfile_freq_sup20_conf75.txt', \"r\").readlines()\n",
    "f2 = [line.strip('\\n') for line in f2]\n",
    "f2 = [line.split('<-') for line in f2 if '100']\n",
    "f3 = [line for line in f2 if '100' in line[0].strip(' ')]\n",
    "f4 = [line for line in f2 if '200' in line[0].strip(' ')]\n",
    "print 'Top 10 Association Rules In Terms of Confidence with Head 100:', len(f3)\n",
    "print 'Top 10 Association Rules In Terms of Confidence with Head 200:', len(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Association Rules with 100 as Head by Confidence: \n",
      "['4', '16', '6', '100']\n",
      "['4', '16', '100']\n",
      "['4', '14', '16', '6', '100']\n",
      "['4', '14', '16', '100']\n",
      "['4', '5', '16', '6', '100']\n",
      "['4', '5', '16', '100']\n",
      "['4', '14', '5', '16', '6', '100']\n",
      "['4', '14', '5', '16', '100']\n",
      "['4', '13', '16', '6', '100']\n",
      "['4', '13', '16', '100']\n",
      "Top 10 Association Rules with 200 as Head by Confidence: \n",
      "['9', '8', '3', '200']\n",
      "['9', '7', '200']\n",
      "['9', '7', '3', '200']\n",
      "['9', '7', '8', '200']\n",
      "['9', '8', '16', '200']\n",
      "['9', '7', '8', '3', '200']\n",
      "['9', '8', '3', '16', '200']\n",
      "['9', '7', '16', '200']\n",
      "['9', '7', '8', '16', '200']\n",
      "['1', '3', '200']\n",
      "Number of rules with above 75% confidence and 100 as head 70\n",
      "Number of rules with above 75% confidence and 200 as head 105\n"
     ]
    }
   ],
   "source": [
    "f2 = open('outfile_freq_sup20_conf75.txt', \"r\").readlines()\n",
    "f2 = [line.strip('\\n') for line in f2]\n",
    "f2 = [line.split('<-') for line in f2 if '100']\n",
    "f2 = [map(lambda x: x.strip(), line) for line in f2]\n",
    "f2 = [line for line in f2]\n",
    "\n",
    "imps=[]\n",
    "supps=[]\n",
    "d={}\n",
    "counter=0\n",
    "for line in f2:\n",
    "    #print line\n",
    "    \n",
    "    #print \"head:\\t\",line[0],\"left:\\t\",line[1].split(\"(\")[0].strip('').split(' ') ,\"\\t\",\"right:\\t\",line[1].split(\",\")[-1][:-1]\n",
    "\n",
    "    d[counter]=((line[0], line[1].split(\"(\")[0].strip('').split(' ')), line[1].split(\",\")[-1][:-1] )\n",
    "    counter+=1\n",
    "    \n",
    "\n",
    "\n",
    "for k,v in d.items():\n",
    "    \n",
    "    d[k] = (v[0], v[1].strip(' '))\n",
    "    \n",
    "d= sorted(d.items(), key=lambda x: x[1][1], reverse=True)\n",
    "\n",
    "all100conf=[]\n",
    "all200conf=[]\n",
    "for i in d:\n",
    "    #print i[1]\n",
    "    if '100' in i[1][0][0]:\n",
    "        all100conf.append(i[1])\n",
    "    if '200' in i[1][0][0]:\n",
    "        all200conf.append(i[1])\n",
    "\n",
    "all100rules_imp=[]\n",
    "print 'Top 10 Association Rules with 100 as Head by Confidence: '\n",
    "for item in all100conf[:10]:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all100rules_imp.append(ls1)\n",
    "    \n",
    "all200rules_imp=[]\n",
    "print 'Top 10 Association Rules with 200 as Head by Confidence: '\n",
    "for item in all200conf[:10]:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all200rules_imp.append(ls1)\n",
    "\n",
    "    \n",
    "print 'Number of rules with above 75% confidence and 100 as head', len(all100conf)\n",
    "\n",
    "print 'Number of rules with above 75% confidence and 200 as head', len(all200conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Association Rules with 100 as Head by Confidence: \n",
      "['4', '16', '6', '100']\n",
      "['4', '16', '100']\n",
      "['4', '14', '16', '6', '100']\n",
      "['4', '14', '16', '100']\n",
      "['4', '5', '16', '6', '100']\n",
      "['4', '5', '16', '100']\n",
      "['4', '14', '5', '16', '6', '100']\n",
      "['4', '14', '5', '16', '100']\n",
      "['4', '13', '16', '6', '100']\n",
      "['4', '13', '16', '100']\n",
      "['4', '13', '5', '16', '6', '100']\n",
      "['4', '13', '5', '16', '100']\n",
      "['4', '14', '13', '16', '6', '100']\n",
      "['4', '14', '13', '16', '100']\n",
      "['4', '14', '13', '5', '16', '6', '100']\n",
      "['4', '14', '13', '5', '16', '100']\n",
      "['12', '14', '16', '6', '100']\n",
      "['12', '14', '16', '100']\n",
      "['14', '5', '16', '6', '100']\n",
      "['4', '13', '6', '100']\n",
      "['4', '13', '100']\n",
      "['14', '13', '16', '6', '100']\n",
      "['14', '13', '5', '16', '6', '100']\n",
      "['12', '4', '13', '6', '100']\n",
      "['12', '4', '13', '100']\n",
      "['12', '4', '14', '13', '6', '100']\n",
      "['12', '4', '14', '13', '100']\n",
      "['4', '13', '5', '6', '100']\n",
      "['4', '13', '5', '100']\n",
      "['12', '4', '13', '5', '6', '100']\n",
      "['12', '4', '13', '5', '100']\n",
      "['12', '4', '14', '13', '5', '6', '100']\n",
      "['12', '4', '14', '13', '5', '100']\n",
      "['4', '14', '13', '6', '100']\n",
      "['4', '14', '13', '100']\n",
      "['4', '14', '13', '5', '6', '100']\n",
      "['4', '14', '13', '5', '100']\n",
      "['12', '16', '6', '100']\n",
      "['14', '5', '16', '100']\n",
      "['4', '6', '100']\n",
      "['4', '100']\n",
      "['14', '13', '16', '100']\n",
      "['14', '13', '5', '16', '100']\n",
      "['12', '14', '13', '6', '100']\n",
      "['12', '14', '13', '100']\n",
      "['4', '5', '6', '100']\n",
      "['4', '5', '100']\n",
      "['4', '14', '6', '100']\n",
      "['4', '14', '100']\n",
      "['12', '13', '5', '6', '100']\n",
      "['12', '13', '5', '100']\n",
      "['12', '14', '13', '5', '6', '100']\n",
      "['12', '14', '13', '5', '100']\n",
      "['4', '14', '5', '6', '100']\n",
      "['4', '14', '5', '100']\n",
      "['14', '16', '6', '100']\n",
      "['12', '4', '6', '100']\n",
      "['12', '4', '14', '6', '100']\n",
      "['12', '4', '14', '100']\n",
      "['12', '4', '100']\n",
      "['12', '13', '6', '100']\n",
      "['12', '13', '100']\n",
      "['12', '16', '100']\n",
      "['13', '5', '16', '6', '100']\n",
      "['12', '4', '5', '6', '100']\n",
      "['12', '4', '5', '100']\n",
      "['12', '4', '14', '5', '6', '100']\n",
      "['12', '4', '14', '5', '100']\n",
      "['4', '2', '6', '100']\n",
      "['4', '2', '100']\n",
      "Top 10 Association Rules with 200 as Head by Confidence: \n",
      "['9', '8', '3', '200']\n",
      "['9', '7', '200']\n",
      "['9', '7', '3', '200']\n",
      "['9', '7', '8', '200']\n",
      "['9', '8', '16', '200']\n",
      "['9', '7', '8', '3', '200']\n",
      "['9', '8', '3', '16', '200']\n",
      "['9', '7', '16', '200']\n",
      "['9', '7', '8', '16', '200']\n",
      "['1', '3', '200']\n",
      "['3', '2', '200']\n",
      "['1', '8', '200']\n",
      "['8', '2', '200']\n",
      "['8', '3', '200']\n",
      "['1', '8', '3', '200']\n",
      "['9', '3', '200']\n",
      "['9', '8', '200']\n",
      "['8', '3', '2', '200']\n",
      "['3', '200']\n",
      "['3', '2', '16', '200']\n",
      "['1', '3', '16', '200']\n",
      "['7', '1', '200']\n",
      "['7', '1', '3', '200']\n",
      "['9', '16', '200']\n",
      "['7', '3', '200']\n",
      "['3', '2', '6', '200']\n",
      "['8', '2', '16', '200']\n",
      "['8', '3', '2', '16', '200']\n",
      "['7', '1', '8', '200']\n",
      "['7', '1', '8', '3', '200']\n",
      "['9', '3', '16', '200']\n",
      "['8', '3', '16', '200']\n",
      "['7', '8', '3', '200']\n",
      "['1', '8', '16', '200']\n",
      "['1', '8', '3', '16', '200']\n",
      "['9', '200']\n",
      "['1', '3', '2', '200']\n",
      "['1', '8', '2', '200']\n",
      "['1', '10', '3', '200']\n",
      "['8', '200']\n",
      "['8', '2', '6', '200']\n",
      "['8', '3', '2', '6', '200']\n",
      "['1', '3', '6', '200']\n",
      "['1', '8', '3', '2', '200']\n",
      "['7', '2', '200']\n",
      "['7', '3', '2', '200']\n",
      "['7', '8', '2', '200']\n",
      "['7', '8', '3', '2', '200']\n",
      "['9', '10', '200']\n",
      "['3', '16', '200']\n",
      "['7', '200']\n",
      "['8', '16', '200']\n",
      "['7', '8', '200']\n",
      "['8', '3', '6', '200']\n",
      "['10', '8', '3', '200']\n",
      "['11', '1', '200']\n",
      "['7', '3', '16', '200']\n",
      "['7', '8', '3', '16', '200']\n",
      "['3', '6', '200']\n",
      "['7', '10', '3', '200']\n",
      "['7', '10', '8', '3', '200']\n",
      "['10', '3', '200']\n",
      "['11', '2', '200']\n",
      "['8', '3', '16', '6', '200']\n",
      "['10', '8', '200']\n",
      "['11', '200']\n",
      "['11', '1', '2', '200']\n",
      "['7', '16', '200']\n",
      "['7', '8', '16', '200']\n",
      "['7', '10', '200']\n",
      "['3', '5', '6', '200']\n",
      "['3', '5', '200']\n",
      "['10', '8', '3', '16', '200']\n",
      "['7', '10', '8', '200']\n",
      "['7', '3', '6', '200']\n",
      "['1', '200']\n",
      "['3', '16', '6', '200']\n",
      "['11', '2', '6', '200']\n",
      "['8', '6', '200']\n",
      "['8', '16', '6', '200']\n",
      "['10', '3', '16', '200']\n",
      "['10', '8', '16', '200']\n",
      "['11', '16', '200']\n",
      "['11', '6', '200']\n",
      "['1', '16', '200']\n",
      "['11', '5', '2', '200']\n",
      "['7', '6', '200']\n",
      "['7', '10', '16', '200']\n",
      "['7', '10', '8', '16', '200']\n",
      "['10', '3', '6', '200']\n",
      "['1', '10', '200']\n",
      "['11', '5', '2', '6', '200']\n",
      "['11', '13', '2', '200']\n",
      "['7', '8', '6', '200']\n",
      "['11', '3', '200']\n",
      "['11', '8', '200']\n",
      "['11', '8', '3', '200']\n",
      "['9', '1', '200']\n",
      "['9', '1', '3', '200']\n",
      "['9', '1', '8', '200']\n",
      "['9', '1', '8', '3', '200']\n",
      "['15', '200']\n",
      "['15', '3', '200']\n",
      "['15', '8', '200']\n",
      "['15', '8', '3', '200']\n"
     ]
    }
   ],
   "source": [
    "all100rules_imp=[]\n",
    "print 'Top 10 Association Rules with 100 as Head by Confidence: '\n",
    "for item in all100conf:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all100rules_imp.append(ls1)\n",
    "    \n",
    "all200rules_imp=[]\n",
    "print 'Top 10 Association Rules with 200 as Head by Confidence: '\n",
    "for item in all200conf:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all200rules_imp.append(ls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 6, 16, 100],\n",
       " [4, 16, 100],\n",
       " [4, 6, 14, 16, 100],\n",
       " [4, 14, 16, 100],\n",
       " [4, 5, 6, 16, 100],\n",
       " [4, 5, 16, 100],\n",
       " [4, 5, 6, 14, 16, 100],\n",
       " [4, 5, 14, 16, 100],\n",
       " [4, 6, 13, 16, 100],\n",
       " [4, 13, 16, 100]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all100rules_imp = [map(int, line) for line in all100rules_imp]\n",
    "all100rules_imp = [sorted(line) for line in all100rules_imp]\n",
    "all100rules_imp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 8, 9, 200],\n",
       " [7, 9, 200],\n",
       " [3, 7, 9, 200],\n",
       " [7, 8, 9, 200],\n",
       " [8, 9, 16, 200],\n",
       " [3, 7, 8, 9, 200],\n",
       " [3, 8, 9, 16, 200],\n",
       " [7, 9, 16, 200],\n",
       " [7, 8, 9, 16, 200],\n",
       " [1, 3, 200]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all200rules_imp = [map(int, line) for line in all200rules_imp]\n",
    "all200rules_imp = [sorted(line) for line in all200rules_imp]\n",
    "all200rules_imp[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6], [6, 16], [16], [], [2, 6], [2, 6, 16], [2, 16], [2], [5, 6], [5, 16]]\n",
      "Number of rows: 807\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "# if set(x1) < set(x2) == is x1 a subset of x2 // best logic ever\n",
    "f = open('outfile.txt', 'r')\n",
    "f = [line.strip('\\n') for line in f.readlines()]\n",
    "f = [line.split() for line in f]\n",
    "f = [line[:-1] for line in f]\n",
    "f = [map(int, line) for line in f]\n",
    "f = [sorted(line) for line in f]\n",
    "newf = [line for line in f if 200 == line[-1] or 100 == line[-1]]\n",
    "y = np.array([line[-1] for line in newf])\n",
    "X = [line[:-1] for line in newf]\n",
    "print X[:10]\n",
    "print 'Number of rows:', len(X) #rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5], [5, 14], [5, 13], [13, 14], [13, 14], [5, 13, 14], [6, 13, 14], [7], [2, 5], [12]]\n",
      "Number of cols:  1171\n"
     ]
    }
   ],
   "source": [
    "# we want a list of ints in ascending order\n",
    "each_rule_body=[]\n",
    "for i in d:\n",
    "    ruleBody=filter(None, i[1][0][1])\n",
    "    ruleBody=map(int, ruleBody)\n",
    "    ruleBody = sorted(ruleBody)\n",
    "    each_rule_body.append(ruleBody)\n",
    "    #print ruleBody\n",
    "    \n",
    "print each_rule_body[:10]\n",
    "print 'Number of cols: ' , len(each_rule_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "      <th>1170</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9     ...      1162  1163  1164  1165  1166  \\\n",
       "0  0  0  0  0  0  0  1  0  0  0     ...         0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0     ...         0     0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0     ...         0     0     1     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0     ...         0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  0  0  0     ...         0     0     0     0     0   \n",
       "\n",
       "   1167  1168  1169  1170  prediction  \n",
       "0     0     0     0     0         200  \n",
       "1     0     0     0     0         200  \n",
       "2     0     0     0     0         200  \n",
       "3     0     0     0     0         200  \n",
       "4     0     0     0     0         200  \n",
       "\n",
       "[5 rows x 1172 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.zeros((len(X), len(each_rule_body)), dtype=np.int8)\n",
    "r,c = M.shape\n",
    "\n",
    "for i in range(0,r):\n",
    "    for j in range(0,c):\n",
    "        if(set(f[i]) < set(each_rule_body[j])):\n",
    "            M[i][j]=1\n",
    "            \n",
    "df_M = pd.DataFrame(M)\n",
    "\n",
    "df_M[\"prediction\"]=y\n",
    "df_M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 1171) \t(605,)\n",
      "(202, 1171) \t(202,)\n",
      "3-Fold CV Average-Accuracy: 0.70 (+/- 0.01)\n",
      "3-Fold CV Standard Deviation: 0.01\n",
      "Odds ratio: (3.3442622950819674, 0.32882872926911294)\n"
     ]
    }
   ],
   "source": [
    "X = df_M.ix[:,0:-1].as_matrix()\n",
    "\n",
    "# This holds out the last 1/4 for parameter tuning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print X_train.shape,\"\\t\" ,y_train.shape\n",
    "print X_test.shape,\"\\t\", y_test.shape\n",
    " \n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=3)\n",
    "print(\"3-Fold CV Average-Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print('3-Fold CV Standard Deviation: %0.2f' % (scores.std()))\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print 'Odds ratio:',  stats.fisher_exact(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'linear', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.676 (+/-0.002) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.676 (+/-0.002) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.678 (+/-0.006) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.676 (+/-0.002) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.688 (+/-0.019) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.678 (+/-0.006) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.694 (+/-0.011) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.688 (+/-0.019) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "0.696 (+/-0.012) for {'kernel': 'linear', 'C': 1}\n",
      "0.694 (+/-0.011) for {'kernel': 'linear', 'C': 10}\n",
      "0.694 (+/-0.011) for {'kernel': 'linear', 'C': 100}\n",
      "0.694 (+/-0.011) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        100       0.60      0.05      0.09        64\n",
      "        200       0.69      0.99      0.81       138\n",
      "\n",
      "avg / total       0.66      0.69      0.58       202\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "print(\"# Tuning hyper-parameters for %s\" % 'accuracy')\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=3,\n",
    "                   scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print\n",
    "print(clf.best_params_)\n",
    "print\n",
    "print(\"Grid scores on development set:\")\n",
    "print\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
