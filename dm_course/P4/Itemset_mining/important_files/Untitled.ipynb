{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## outfile_freq_sup20.txt\t\n",
    "\n",
    "## outfile_freq_sup20_conf75.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get the number of s20 hits that contain 100\n",
    "\n",
    "## Get the number of s20 hits that contain 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-1cd580c6bc3d>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-1cd580c6bc3d>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    print 'Frequent Items Containing 100: ', hits100\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f = open('outfile_freq_sup20.txt', \"r\").readlines()\n",
    "f = [line.strip('\\n') for line in f]\n",
    "f = [line.split(\",\") for line in f]\n",
    "f = [line[:-1] for line in f]\n",
    "\n",
    "itemSets = []\n",
    "sups = []\n",
    "hits100=0\n",
    "hits200=0\n",
    "d={}\n",
    "counter=0\n",
    "for line in f:\n",
    "    \n",
    "    if '100' in line[:-1]:\n",
    "        hits100+=1\n",
    "    if '200' in line[:-1]:\n",
    "        hits200+=1\n",
    "    itemSets.append(line[:-1])\n",
    "    sups.append(line[-1])\n",
    "    d[counter]=(line[:-1], line[-1])\n",
    "    counter+=1\n",
    "    \n",
    "print 'Frequent Items Containing 100: ', hits100\n",
    "print 'Frequent Items Containing 200: ', hits200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Get top 10 Highest Support Frequent Itemsets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Frequent Item sets with Highest Support\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, (['6'], '0.776316')),\n",
       " (2, (['16'], '0.644737')),\n",
       " (6, (['200'], '0.631579')),\n",
       " (13, (['2'], '0.605263')),\n",
       " (22, (['5'], '0.592105')),\n",
       " (14, (['5', '6'], '0.578947')),\n",
       " (36, (['14'], '0.565789')),\n",
       " (63, (['13'], '0.565789')),\n",
       " (79, (['3'], '0.552632')),\n",
       " (23, (['14', '6'], '0.539474'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Top 10 Most Frequent Item sets with Highest Support'\n",
    "sorted(d.items(), key=lambda x: x[1][1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Top 10 Association Rules In Terms of Confidence with Head 100\n",
    "# Top 10 Association Rules In Terms of Confidence with Head 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Association Rules In Terms of Confidence with Head 100: 70\n",
      "Top 10 Association Rules In Terms of Confidence with Head 200: 105\n"
     ]
    }
   ],
   "source": [
    "f2 = open('outfile_freq_sup20_conf75.txt', \"r\").readlines()\n",
    "f2 = [line.strip('\\n') for line in f2]\n",
    "f2 = [line.split('<-') for line in f2 if '100']\n",
    "f3 = [line for line in f2 if '100' in line[0].strip(' ')]\n",
    "f4 = [line for line in f2 if '200' in line[0].strip(' ')]\n",
    "print 'Top 10 Association Rules In Terms of Confidence with Head 100:', len(f3)\n",
    "print 'Top 10 Association Rules In Terms of Confidence with Head 200:', len(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Association Rules with 100 as Head by Confidence: \n",
      "['4', '16', '6', '100']\n",
      "['4', '16', '100']\n",
      "['4', '14', '16', '6', '100']\n",
      "['4', '14', '16', '100']\n",
      "['4', '5', '16', '6', '100']\n",
      "['4', '5', '16', '100']\n",
      "['4', '14', '5', '16', '6', '100']\n",
      "['4', '14', '5', '16', '100']\n",
      "['4', '13', '16', '6', '100']\n",
      "['4', '13', '16', '100']\n",
      "Top 10 Association Rules with 200 as Head by Confidence: \n",
      "['9', '8', '3', '200']\n",
      "['9', '7', '200']\n",
      "['9', '7', '3', '200']\n",
      "['9', '7', '8', '200']\n",
      "['9', '8', '16', '200']\n",
      "['9', '7', '8', '3', '200']\n",
      "['9', '8', '3', '16', '200']\n",
      "['9', '7', '16', '200']\n",
      "['9', '7', '8', '16', '200']\n",
      "['1', '3', '200']\n",
      "Number of rules with above 75% confidence and 100 as head 70\n",
      "Number of rules with above 75% confidence and 200 as head 105\n"
     ]
    }
   ],
   "source": [
    "f2 = open('outfile_freq_sup20_conf75.txt', \"r\").readlines()\n",
    "f2 = [line.strip('\\n') for line in f2]\n",
    "f2 = [line.split('<-') for line in f2 if '100']\n",
    "f2 = [map(lambda x: x.strip(), line) for line in f2]\n",
    "f2 = [line for line in f2]\n",
    "\n",
    "imps=[]\n",
    "supps=[]\n",
    "d={}\n",
    "counter=0\n",
    "for line in f2:\n",
    "    #print line\n",
    "    \n",
    "    #print \"head:\\t\",line[0],\"left:\\t\",line[1].split(\"(\")[0].strip('').split(' ') ,\"\\t\",\"right:\\t\",line[1].split(\",\")[-1][:-1]\n",
    "\n",
    "    d[counter]=((line[0], line[1].split(\"(\")[0].strip('').split(' ')), line[1].split(\",\")[-1][:-1] )\n",
    "    counter+=1\n",
    "    \n",
    "\n",
    "\n",
    "for k,v in d.items():\n",
    "    \n",
    "    d[k] = (v[0], v[1].strip(' '))\n",
    "    \n",
    "d= sorted(d.items(), key=lambda x: x[1][1], reverse=True)\n",
    "\n",
    "all100conf=[]\n",
    "all200conf=[]\n",
    "for i in d:\n",
    "    #print i[1]\n",
    "    if '100' in i[1][0][0]:\n",
    "        all100conf.append(i[1])\n",
    "    if '200' in i[1][0][0]:\n",
    "        all200conf.append(i[1])\n",
    "\n",
    "all100rules_imp=[]\n",
    "print 'Top 10 Association Rules with 100 as Head by Confidence: '\n",
    "for item in all100conf[:10]:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all100rules_imp.append(ls1)\n",
    "    \n",
    "all200rules_imp=[]\n",
    "print 'Top 10 Association Rules with 200 as Head by Confidence: '\n",
    "for item in all200conf[:10]:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all200rules_imp.append(ls1)\n",
    "\n",
    "    \n",
    "print 'Number of rules with above 75% confidence and 100 as head', len(all100conf)\n",
    "\n",
    "print 'Number of rules with above 75% confidence and 200 as head', len(all200conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Association Rules with 100 as Head by Confidence: \n",
      "['4', '16', '6', '100']\n",
      "['4', '16', '100']\n",
      "['4', '14', '16', '6', '100']\n",
      "['4', '14', '16', '100']\n",
      "['4', '5', '16', '6', '100']\n",
      "['4', '5', '16', '100']\n",
      "['4', '14', '5', '16', '6', '100']\n",
      "['4', '14', '5', '16', '100']\n",
      "['4', '13', '16', '6', '100']\n",
      "['4', '13', '16', '100']\n",
      "['4', '13', '5', '16', '6', '100']\n",
      "['4', '13', '5', '16', '100']\n",
      "['4', '14', '13', '16', '6', '100']\n",
      "['4', '14', '13', '16', '100']\n",
      "['4', '14', '13', '5', '16', '6', '100']\n",
      "['4', '14', '13', '5', '16', '100']\n",
      "['12', '14', '16', '6', '100']\n",
      "['12', '14', '16', '100']\n",
      "['14', '5', '16', '6', '100']\n",
      "['4', '13', '6', '100']\n",
      "['4', '13', '100']\n",
      "['14', '13', '16', '6', '100']\n",
      "['14', '13', '5', '16', '6', '100']\n",
      "['12', '4', '13', '6', '100']\n",
      "['12', '4', '13', '100']\n",
      "['12', '4', '14', '13', '6', '100']\n",
      "['12', '4', '14', '13', '100']\n",
      "['4', '13', '5', '6', '100']\n",
      "['4', '13', '5', '100']\n",
      "['12', '4', '13', '5', '6', '100']\n",
      "['12', '4', '13', '5', '100']\n",
      "['12', '4', '14', '13', '5', '6', '100']\n",
      "['12', '4', '14', '13', '5', '100']\n",
      "['4', '14', '13', '6', '100']\n",
      "['4', '14', '13', '100']\n",
      "['4', '14', '13', '5', '6', '100']\n",
      "['4', '14', '13', '5', '100']\n",
      "['12', '16', '6', '100']\n",
      "['14', '5', '16', '100']\n",
      "['4', '6', '100']\n",
      "['4', '100']\n",
      "['14', '13', '16', '100']\n",
      "['14', '13', '5', '16', '100']\n",
      "['12', '14', '13', '6', '100']\n",
      "['12', '14', '13', '100']\n",
      "['4', '5', '6', '100']\n",
      "['4', '5', '100']\n",
      "['4', '14', '6', '100']\n",
      "['4', '14', '100']\n",
      "['12', '13', '5', '6', '100']\n",
      "['12', '13', '5', '100']\n",
      "['12', '14', '13', '5', '6', '100']\n",
      "['12', '14', '13', '5', '100']\n",
      "['4', '14', '5', '6', '100']\n",
      "['4', '14', '5', '100']\n",
      "['14', '16', '6', '100']\n",
      "['12', '4', '6', '100']\n",
      "['12', '4', '14', '6', '100']\n",
      "['12', '4', '14', '100']\n",
      "['12', '4', '100']\n",
      "['12', '13', '6', '100']\n",
      "['12', '13', '100']\n",
      "['12', '16', '100']\n",
      "['13', '5', '16', '6', '100']\n",
      "['12', '4', '5', '6', '100']\n",
      "['12', '4', '5', '100']\n",
      "['12', '4', '14', '5', '6', '100']\n",
      "['12', '4', '14', '5', '100']\n",
      "['4', '2', '6', '100']\n",
      "['4', '2', '100']\n",
      "Top 10 Association Rules with 200 as Head by Confidence: \n",
      "['9', '8', '3', '200']\n",
      "['9', '7', '200']\n",
      "['9', '7', '3', '200']\n",
      "['9', '7', '8', '200']\n",
      "['9', '8', '16', '200']\n",
      "['9', '7', '8', '3', '200']\n",
      "['9', '8', '3', '16', '200']\n",
      "['9', '7', '16', '200']\n",
      "['9', '7', '8', '16', '200']\n",
      "['1', '3', '200']\n",
      "['3', '2', '200']\n",
      "['1', '8', '200']\n",
      "['8', '2', '200']\n",
      "['8', '3', '200']\n",
      "['1', '8', '3', '200']\n",
      "['9', '3', '200']\n",
      "['9', '8', '200']\n",
      "['8', '3', '2', '200']\n",
      "['3', '200']\n",
      "['3', '2', '16', '200']\n",
      "['1', '3', '16', '200']\n",
      "['7', '1', '200']\n",
      "['7', '1', '3', '200']\n",
      "['9', '16', '200']\n",
      "['7', '3', '200']\n",
      "['3', '2', '6', '200']\n",
      "['8', '2', '16', '200']\n",
      "['8', '3', '2', '16', '200']\n",
      "['7', '1', '8', '200']\n",
      "['7', '1', '8', '3', '200']\n",
      "['9', '3', '16', '200']\n",
      "['8', '3', '16', '200']\n",
      "['7', '8', '3', '200']\n",
      "['1', '8', '16', '200']\n",
      "['1', '8', '3', '16', '200']\n",
      "['9', '200']\n",
      "['1', '3', '2', '200']\n",
      "['1', '8', '2', '200']\n",
      "['1', '10', '3', '200']\n",
      "['8', '200']\n",
      "['8', '2', '6', '200']\n",
      "['8', '3', '2', '6', '200']\n",
      "['1', '3', '6', '200']\n",
      "['1', '8', '3', '2', '200']\n",
      "['7', '2', '200']\n",
      "['7', '3', '2', '200']\n",
      "['7', '8', '2', '200']\n",
      "['7', '8', '3', '2', '200']\n",
      "['9', '10', '200']\n",
      "['3', '16', '200']\n",
      "['7', '200']\n",
      "['8', '16', '200']\n",
      "['7', '8', '200']\n",
      "['8', '3', '6', '200']\n",
      "['10', '8', '3', '200']\n",
      "['11', '1', '200']\n",
      "['7', '3', '16', '200']\n",
      "['7', '8', '3', '16', '200']\n",
      "['3', '6', '200']\n",
      "['7', '10', '3', '200']\n",
      "['7', '10', '8', '3', '200']\n",
      "['10', '3', '200']\n",
      "['11', '2', '200']\n",
      "['8', '3', '16', '6', '200']\n",
      "['10', '8', '200']\n",
      "['11', '200']\n",
      "['11', '1', '2', '200']\n",
      "['7', '16', '200']\n",
      "['7', '8', '16', '200']\n",
      "['7', '10', '200']\n",
      "['3', '5', '6', '200']\n",
      "['3', '5', '200']\n",
      "['10', '8', '3', '16', '200']\n",
      "['7', '10', '8', '200']\n",
      "['7', '3', '6', '200']\n",
      "['1', '200']\n",
      "['3', '16', '6', '200']\n",
      "['11', '2', '6', '200']\n",
      "['8', '6', '200']\n",
      "['8', '16', '6', '200']\n",
      "['10', '3', '16', '200']\n",
      "['10', '8', '16', '200']\n",
      "['11', '16', '200']\n",
      "['11', '6', '200']\n",
      "['1', '16', '200']\n",
      "['11', '5', '2', '200']\n",
      "['7', '6', '200']\n",
      "['7', '10', '16', '200']\n",
      "['7', '10', '8', '16', '200']\n",
      "['10', '3', '6', '200']\n",
      "['1', '10', '200']\n",
      "['11', '5', '2', '6', '200']\n",
      "['11', '13', '2', '200']\n",
      "['7', '8', '6', '200']\n",
      "['11', '3', '200']\n",
      "['11', '8', '200']\n",
      "['11', '8', '3', '200']\n",
      "['9', '1', '200']\n",
      "['9', '1', '3', '200']\n",
      "['9', '1', '8', '200']\n",
      "['9', '1', '8', '3', '200']\n",
      "['15', '200']\n",
      "['15', '3', '200']\n",
      "['15', '8', '200']\n",
      "['15', '8', '3', '200']\n"
     ]
    }
   ],
   "source": [
    "all100rules_imp=[]\n",
    "print 'Top 10 Association Rules with 100 as Head by Confidence: '\n",
    "for item in all100conf:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all100rules_imp.append(ls1)\n",
    "    \n",
    "all200rules_imp=[]\n",
    "print 'Top 10 Association Rules with 200 as Head by Confidence: '\n",
    "for item in all200conf:\n",
    "    #print filter(None, item[0][1]), \"->\" ,item[0][0]\n",
    "    ls1= filter(None, item[0][1])\n",
    "    ls1.append(item[0][0])\n",
    "    print ls1\n",
    "    all200rules_imp.append(ls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 6, 16, 100],\n",
       " [4, 16, 100],\n",
       " [4, 6, 14, 16, 100],\n",
       " [4, 14, 16, 100],\n",
       " [4, 5, 6, 16, 100],\n",
       " [4, 5, 16, 100],\n",
       " [4, 5, 6, 14, 16, 100],\n",
       " [4, 5, 14, 16, 100],\n",
       " [4, 6, 13, 16, 100],\n",
       " [4, 13, 16, 100]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all100rules_imp = [map(int, line) for line in all100rules_imp]\n",
    "all100rules_imp = [sorted(line) for line in all100rules_imp]\n",
    "all100rules_imp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 8, 9, 200],\n",
       " [7, 9, 200],\n",
       " [3, 7, 9, 200],\n",
       " [7, 8, 9, 200],\n",
       " [8, 9, 16, 200],\n",
       " [3, 7, 8, 9, 200],\n",
       " [3, 8, 9, 16, 200],\n",
       " [7, 9, 16, 200],\n",
       " [7, 8, 9, 16, 200],\n",
       " [1, 3, 200]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all200rules_imp = [map(int, line) for line in all200rules_imp]\n",
    "all200rules_imp = [sorted(line) for line in all200rules_imp]\n",
    "all200rules_imp[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Now lets create a numpy matrix which contains rows representing our original rows in our dataset and columns representing each frequent word rule body, then for each of the rows which contain a frequent word body which is above the 75% conf from our previous lists, then light it up with a 1, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-0a10783f7348>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-0a10783f7348>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    print X[:10]\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "# if set(x1) < set(x2) == is x1 a subset of x2 // best logic ever\n",
    "f = open('outfile.txt', 'r')\n",
    "f = [line.strip('\\n') for line in f.readlines()]\n",
    "f = [line.split() for line in f]\n",
    "f = [line[:-1] for line in f]\n",
    "f = [map(int, line) for line in f]\n",
    "f = [sorted(line) for line in f]\n",
    "newf = [line for line in f if 200 == line[-1] or 100 == line[-1]]\n",
    "y = np.array([line[-1] for line in newf])\n",
    "X = [line[:-1] for line in newf]\n",
    "print X[:10]\n",
    "print 'Number of rows:', len(X) #rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5], [5, 14], [5, 13], [13, 14], [13, 14], [5, 13, 14], [6, 13, 14], [7], [2, 5], [12]]\n",
      "Number of cols:  1171\n"
     ]
    }
   ],
   "source": [
    "# we want a list of ints in ascending order\n",
    "each_rule_body=[]\n",
    "for i in d:\n",
    "    ruleBody=filter(None, i[1][0][1])\n",
    "    ruleBody=map(int, ruleBody)\n",
    "    ruleBody = sorted(ruleBody)\n",
    "    each_rule_body.append(ruleBody)\n",
    "    #print ruleBody\n",
    "    \n",
    "print each_rule_body[:10]\n",
    "print 'Number of cols: ' , len(each_rule_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "M = np.zeros((len(X), len(each_rule_body)), dtype=np.int8)\n",
    "r,c = M.shape\n",
    "\n",
    "for i in range(0,r):\n",
    "    for j in range(0,c):\n",
    "        if(set(f[i]) < set(each_rule_body[j])):\n",
    "            M[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8590d713158d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_M\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2485\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2486\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2657\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2798\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "df_M = pd.DataFrame(M)\n",
    "\n",
    "df_M[\"prediction\"]=y\n",
    "df_M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-5c428c8e20b4>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-5c428c8e20b4>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print X_train.shape,\"\\t\" ,y_train.shape\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = df_M.ix[:,0:-1].as_matrix()\n",
    "\n",
    "# This holds out the last 1/4 for parameter tuning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print X_train.shape,\"\\t\" ,y_train.shape\n",
    "print X_test.shape,\"\\t\", y_test.shape\n",
    " \n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, X, y, cv=3)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
